# streamlit_womens_health_app.py
# Smart Women's Health Analyzer
# Usage (Streamlit): streamlit run streamlit_womens_health_app.py
# Fallback usage (no streamlit): python streamlit_womens_health_app.py --file health_data.csv

"""
Ø§ÛŒÙ† Ù†Ø³Ø®Ù‡ Ø·ÙˆØ±ÛŒ Ù†ÙˆØ´ØªÙ‡ Ø´Ø¯Ù‡ Ú©Ù‡ Ø¯Ø± ØµÙˆØ±Øª Ø¹Ø¯Ù… Ù†ØµØ¨ streamlit (Ø®Ø·Ø§ÛŒ ModuleNotFoundError)
Ø¨Ù‡â€ŒØµÙˆØ±Øª fallback Ø¯Ø± Ù…Ø­ÛŒØ· Ø®Ø· ÙØ±Ù…Ø§Ù† ÛŒØ§ Jupyter Ø§Ø¬Ø±Ø§ Ø´ÙˆØ¯ Ùˆ Ù‡Ù…Ø§Ù† ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§ Ø±Ø§ ØªÙˆÙ„ÛŒØ¯ Ú©Ù†Ø¯.

Ù‚Ø§Ø¨Ù„ÛŒØªâ€ŒÙ‡Ø§:
- Ø®ÙˆØ§Ù†Ø¯Ù† CSV ÛŒØ§ Excel
- ØªØ´Ø®ÛŒØµ Ø®ÙˆØ¯Ú©Ø§Ø± Ø³ØªÙˆÙ† Ù‡Ø¯Ù (Ù…Ø«Ù„Ø§Ù‹ *score, balance, stress, anemia, risk*)
- Ù¾ÛŒØ´â€Œâ€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ Ø³Ø§Ø¯Ù‡ Ùˆ ØªØ¨Ø¯ÛŒÙ„ categorical Ø¨Ù‡ Ø¹Ø¯Ø¯
- Ø¢Ù…ÙˆØ²Ø´ RandomForest Ùˆ Ú¯Ø²Ø§Ø±Ø´ RÂ² Ùˆ MAE
- Ø°Ø®ÛŒØ±Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù†Ù…ÙˆØ¯Ø§Ø±Ù‡Ø§ Ø¨Ù‡â€ŒØµÙˆØ±Øª HTML (Plotly) Ùˆ CSV Ø®Ø±ÙˆØ¬ÛŒ Ø¨Ø§ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ
- ØªØ§Ø¨Ø¹ ØªØ¹Ø§Ù…Ù„ÛŒ Ø³Ø§Ø¯Ù‡ (CLI) Ø¨Ø±Ø§ÛŒ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ ÛŒÚ© Ø±Ú©ÙˆØ±Ø¯ Ø¬Ø¯ÛŒØ¯

Ù†Ú©ØªÙ‡: Ø§Ú¯Ø± Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡ÛŒØ¯ Ù†Ø³Ø®Ù‡Ù” ØªØ­Øªâ€ŒÙˆØ¨ (streamlit) Ø±Ø§ Ø§Ø¬Ø±Ø§ Ú©Ù†ÛŒØ¯ØŒ Ø§Ø¨ØªØ¯Ø§ streamlit Ø±Ø§ Ù†ØµØ¨ Ú©Ù†ÛŒØ¯:
    pip install streamlit

"""

import sys
import os
import argparse
import math
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.io as pio
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score, mean_absolute_error

# Try to import streamlit; if not available, fall back to CLI/notebook mode
try:
    import streamlit as st
    STREAMLIT_AVAILABLE = True
except Exception:
    STREAMLIT_AVAILABLE = False

# -------------------------
# Core analysis functions
# -------------------------

def load_data(path):
    """Load CSV or Excel file into DataFrame."""
    if str(path).lower().endswith('.xlsx') or str(path).lower().endswith('.xls'):
        df = pd.read_excel(path)
    else:
        df = pd.read_csv(path)
    return df


def auto_detect_target(df):
    """Return a target column name detected automatically or None."""
    candidates = [c for c in df.columns if any(k in c.lower() for k in ['score','balance','stress','anemia','risk'])]
    return candidates[0] if candidates else None


def preprocess(df, target):
    """Simple preprocessing: drop all-empty rows, fill numeric NaNs with mean,
    convert non-numeric columns to categorical codes.
    Returns X, y and cleaned df.
    """
    df = df.dropna(how='all').copy()
    if target not in df.columns:
        raise ValueError(f"Target column '{target}' not found in data.")

    # fill target NaNs with mean
    y = df[target].copy()
    if y.isnull().any():
        y = y.fillna(y.mean())

    X = df.drop(columns=[target]).copy()

    # convert booleans to int
    for col in X.select_dtypes(include=['bool']).columns:
        X[col] = X[col].astype(int)

    # convert non-numeric to categorical codes
    for col in X.columns:
        if not pd.api.types.is_numeric_dtype(X[col]):
            X[col] = X[col].astype('category').cat.codes

    # drop columns that are all NaN or constant
    X = X.dropna(axis=1, how='all')
    nunique = X.nunique()
    const_cols = nunique[nunique <= 1].index.tolist()
    if const_cols:
        X = X.drop(columns=const_cols)

    return X, y, df


def train_and_report(X, y, test_size=0.2, n_estimators=120, random_state=42, output_prefix='output'):
    """Train RandomForestRegressor and produce metrics and visual outputs.
    Returns model and dict of metrics and file paths for saved artifacts.
    """
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=int(random_state))
    model = RandomForestRegressor(n_estimators=int(n_estimators), random_state=int(random_state))
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    r2 = r2_score(y_test, y_pred)
    mae = mean_absolute_error(y_test, y_pred)

    # Feature importances
    importances = pd.Series(model.feature_importances_, index=X.columns).sort_values(ascending=True)

    # Save importance plot as HTML
    fig_imp = px.bar(importances, orientation='h', title='Feature Importances')
    imp_html = f"{output_prefix}_feature_importances.html"
    pio.write_html(fig_imp, file=imp_html, auto_open=False)

    # If number of features is small, save correlation heatmap
    heatmap_html = None
    if X.shape[1] <= 25:
        corr = pd.concat([X, y], axis=1).corr()
        fig_corr = px.imshow(corr, text_auto=True, aspect='auto', title='Correlation heatmap')
        heatmap_html = f"{output_prefix}_correlation_heatmap.html"
        pio.write_html(fig_corr, file=heatmap_html, auto_open=False)

    # Approximate mean effect when setting to 75th percentile
    base = model.predict(X_test).mean()
    effects = {}
    for col in X.columns:
        X_tmp = X_test.copy()
        q = X_tmp[col].quantile(0.75)
        X_tmp[col] = q
        effects[col] = model.predict(X_tmp).mean() - base
    effects_ser = pd.Series(effects).sort_values()
    fig_eff = px.bar(effects_ser, orientation='h', title='Approx. mean effect when setting feature to 75th percentile')
    eff_html = f"{output_prefix}_effects.html"
    pio.write_html(fig_eff, file=eff_html, auto_open=False)

    artifacts = {
        'r2': r2,
        'mae': mae,
        'feature_importances': importances,
        'feature_importances_html': imp_html,
        'correlation_html': heatmap_html,
        'effects_html': eff_html,
        'model': model,
    }
    return artifacts


def predict_interactive(model, X_columns):
    """CLI interactive prompt to enter values for each feature and get prediction."""
    print('\nEnter values for the following features (press Enter to use mean):')
    vals = {}
    for col in X_columns:
        while True:
            try:
                s = input(f"  {col}: ")
                if s.strip() == '':
                    vals[col] = None
                    break
                else:
                    vals[col] = float(s)
                    break
            except Exception as e:
                print('ÙˆØ±ÙˆØ¯ÛŒ Ù†Ø§Ù…Ø¹ØªØ¨Ø±ØŒ Ù„Ø·ÙØ§Ù‹ Ù…Ù‚Ø¯Ø§Ø± Ø¹Ø¯Ø¯ÛŒ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯ ÛŒØ§ Enter Ø¨Ø²Ù†ÛŒØ¯.')
    # Build DataFrame
    df_in = pd.DataFrame([vals])
    # replace Nones with NaN
    df_in = df_in.astype('float')
    return df_in

# -------------------------
# CLI / Notebook fallback
# -------------------------

def run_cli(file_path, target=None, test_size=0.2, n_estimators=120, random_state=42, output_prefix='output'):
    print('Running Smart Women\'s Health Analyzer in CLI/fallback mode')
    print(f'Loading file: {file_path}')
    df = load_data(file_path)
    print('Columns found:', list(df.columns))

    if target is None:
        target = auto_detect_target(df)
        if target:
            print(f"Auto-detected target column: {target}")
        else:
            raise ValueError('No target column detected automatically. Please provide the --target argument.')
    else:
        print(f'Using target column: {target}')

    X, y, df_clean = preprocess(df, target)
    print(f'Features used: {list(X.columns)}')
    artifacts = train_and_report(X, y, test_size=test_size, n_estimators=n_estimators, random_state=random_state, output_prefix=output_prefix)

    print('\nModel performance:')
    print(f"  R2 = {artifacts['r2']:.4f}")
    print(f"  MAE = {artifacts['mae']:.4f}")
    print('\nSaved artifacts:')
    print('  - Feature importances HTML:', artifacts['feature_importances_html'])
    if artifacts['correlation_html']:
        print('  - Correlation heatmap HTML:', artifacts['correlation_html'])
    print('  - Effects HTML:', artifacts['effects_html'])

    # Save predictions for full dataset
    preds = artifacts['model'].predict(X)
    out_df = df_clean.copy()
    out_df['predicted_' + str(target)] = preds
    out_csv = f"{output_prefix}_predictions.csv"
    out_df.to_csv(out_csv, index=False)
    print('  - Predictions CSV:', out_csv)

    # Ask user if they want to do interactive prediction
    do_interactive = input('\nDo interactive prediction? (y/N): ').strip().lower() == 'y'
    if do_interactive:
        df_in = predict_interactive(artifacts['model'], X.columns)
        # fill missing with column means
        for c in X.columns:
            if c not in df_in.columns or pd.isna(df_in.at[0,c]):
                df_in.at[0,c] = X[c].mean()
        pred = artifacts['model'].predict(df_in[X.columns])[0]
        print(f"\nPrediction for input: {pred:.2f}")

    print('\nDone.')

# -------------------------
# Streamlit UI (if available)
# -------------------------

def run_streamlit_app():
    # This function contains the same logic as before but only runs when streamlit is available
    st.set_page_config(page_title="Smart Women's Health Analyzer", layout='wide')
    st.title("ğŸŒº Smart Women's Health Analyzer")
    st.write("Ø¢Ù¾Ù„ÙˆØ¯ ÙØ§ÛŒÙ„ CSV/XLSX Ø´Ø§Ù…Ù„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø³Ø¨Ú© Ø²Ù†Ø¯Ú¯ÛŒ Ùˆ ÛŒÚ© Ø³ØªÙˆÙ† Ù‡Ø¯Ù (Ù…Ø«Ù„Ø§Ù‹ Hormonal_balance_score ÛŒØ§ Stress_level)")

    uploaded_file = st.file_uploader("Upload CSV or Excel file", type=['csv','xlsx'])

    if uploaded_file is not None:
        try:
            if str(uploaded_file.name).endswith('.xlsx'):
                df = pd.read_excel(uploaded_file)
            else:
                df = pd.read_csv(uploaded_file)
        except Exception as e:
            st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø®ÙˆØ§Ù†Ø¯Ù† ÙØ§ÛŒÙ„: {e}")
            st.stop()

        st.subheader("ğŸ“Œ Ù¾ÛŒØ´â€ŒÙ†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡")
        st.dataframe(df.head())
        st.markdown(f"**ØªØ¹Ø¯Ø§Ø¯ Ø±Ø¯ÛŒÙ:** {len(df)}  â€”  **Ø³ØªÙˆÙ†â€ŒÙ‡Ø§:** {', '.join(df.columns)}")

        df = df.dropna(how='all')
        candidates = [c for c in df.columns if any(k in c.lower() for k in ['score','balance','stress','anemia','risk'])]

        with st.sidebar:
            st.header("ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù…Ø¯Ù„")
            if candidates:
                target = st.selectbox('Ø§Ù†ØªØ®Ø§Ø¨ Ø³ØªÙˆÙ† Ù‡Ø¯Ù (Ø¯Ø± ØµÙˆØ±Øª ÛŒØ§ÙØªÙ† Ø®ÙˆØ¯Ú©Ø§Ø±)', ['--auto--'] + candidates)
                if target == '--auto--':
                    target = candidates[0]
            else:
                target = st.text_input('Ù†Ø§Ù… Ø³ØªÙˆÙ† Ù‡Ø¯Ù (Ù…Ø«Ù„Ø§Ù‹ Hormonal_balance_score)')

            test_size = st.slider('Ù†Ø³Ø¨Øª ØªØ³Øª (test size)', min_value=0.1, max_value=0.4, value=0.2)
            n_estimators = st.slider('ØªØ¹Ø¯Ø§Ø¯ Ø¯Ø±Ø®ØªØ§Ù† RandomForest', min_value=10, max_value=300, value=120, step=10)
            random_state = st.number_input('Random state (int)', value=42, step=1)
            st.markdown('---')
            st.markdown('Ø¨Ø±Ø§ÛŒ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ ØºÛŒØ±Ø¹Ø¯Ø¯ÛŒØŒ Ø¢Ù†â€ŒÙ‡Ø§ Ø±Ø§ Ø¯Ø± Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ Ø¨Ù‡ Ø¹Ø¯Ø¯ ØªØ¨Ø¯ÛŒÙ„ Ú©Ù†ÛŒØ¯ (one-hot ÛŒØ§ label).')

        if target not in df.columns:
            st.error('Ø³ØªÙˆÙ† Ù‡Ø¯Ù Ù…Ø¹ØªØ¨Ø± Ù†ÛŒØ³Øª. Ù„Ø·ÙØ§Ù‹ Ø³ØªÙˆÙ† Ù…ÙˆØ¬ÙˆØ¯ Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯.')
            st.stop()

        X = df.drop(columns=[target]).copy()
        y = df[target].copy()

        for col in X.columns:
            if not pd.api.types.is_numeric_dtype(X[col]):
                X[col] = X[col].astype('category').cat.codes

        X = X.dropna(axis=1, how='all')
        y = y.fillna(y.mean())

        st.subheader('ğŸ“ˆ Ù…ØµÙˆØ±Ø³Ø§Ø²ÛŒ Ùˆ Ø¨Ø±Ø±Ø³ÛŒ Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ')
        if X.shape[1] <= 8:
            corr = pd.concat([X, y], axis=1).corr()
            fig_corr = px.imshow(corr, text_auto=True, aspect='auto', title='Heatmap Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ')
            st.plotly_chart(fig_corr, use_container_width=True)
        else:
            st.info('Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ø¨Ø³ÛŒØ§Ø± Ø²ÛŒØ§Ø¯ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ heatmap â€” Ø§Ø² Ø¬Ø¯ÙˆÙ„ Ø§Ù‡Ù…ÛŒØª ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯.')

        col1, col2 = st.columns([1,1])
        with col1:
            st.subheader('ØªÙˆØ²ÛŒØ¹ Ù‡Ø¯Ù')
            fig = px.histogram(y, nbins=30, title=f'Distribution of {target}')
            st.plotly_chart(fig, use_container_width=True)

        with col2:
            st.subheader('Ù¾ÛŒØ´â€ŒÙ†Ù…Ø§ÛŒØ´ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¹Ø¯Ø¯ÛŒ')
            st.write(X.describe().T)

        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=int(random_state))
        model = RandomForestRegressor(n_estimators=int(n_estimators), random_state=int(random_state))
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)

        r2 = r2_score(y_test, y_pred)
        mae = mean_absolute_error(y_test, y_pred)

        st.subheader('ğŸ” Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù…Ø¯Ù„')
        st.metric('RÂ² on test', f"{r2:.3f}")
        st.metric('MAE on test', f"{mae:.3f}")

        importances = pd.Series(model.feature_importances_, index=X.columns).sort_values(ascending=True)
        st.subheader('ğŸ’¡ Ø§Ù‡Ù…ÛŒØª ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§')
        fig_imp = px.bar(importances, orientation='h', title='Feature Importances')
        st.plotly_chart(fig_imp, use_container_width=True)

        st.subheader('ğŸ” ØªØ£Ø«ÛŒØ± Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù‡Ø± ÙˆÛŒÚ˜Ú¯ÛŒ (Ø®Ù„Ø§ØµÙ‡)')
        effects = {}
        base = model.predict(X_test).mean()
        for col in X.columns:
            X_tmp = X_test.copy()
            q = X_tmp[col].quantile(0.75)
            X_tmp[col] = q
            effects[col] = model.predict(X_tmp).mean() - base
        effects_ser = pd.Series(effects).sort_values()
        fig_eff = px.bar(effects_ser, orientation='h', title='Approx. mean effect when setting feature to 75th percentile')
        st.plotly_chart(fig_eff, use_container_width=True)

        st.subheader('ğŸ§ª Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ ØªØ¹Ø§Ù…Ù„ÛŒ Ø¨Ø±Ø§ÛŒ Ø±Ú©ÙˆØ±Ø¯ Ø¬Ø¯ÛŒØ¯')
        with st.form(key='input_form'):
            input_data = {}
            for col in X.columns:
                if pd.api.types.is_integer_dtype(X[col]) or pd.api.types.is_float_dtype(X[col]):
                    min_v = float(X[col].min())
                    max_v = float(X[col].max())
                    mean_v = float(X[col].mean())
                    input_data[col] = st.number_input(col, value=mean_v, min_value=min_v, max_value=max_v)
                else:
                    input_data[col] = st.number_input(col, value=0)
            submit = st.form_submit_button('Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ú©Ù†')

        if submit:
            x_new = pd.DataFrame([input_data])[X.columns]
            pred = model.predict(x_new)[0]
            st.success(f'ğŸ”® Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ {target}: {pred:.2f}')

            top_feats = importances.tail(3).index.tolist()[::-1]
            st.markdown('**Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ù‡Ø§ÛŒ Ø§Ø¨ØªØ¯Ø§ÛŒÛŒ (Ù‚ÙˆØ§Ø¹Ø¯ Ø³Ø§Ø¯Ù‡):**')
            for f in top_feats:
                val = x_new[f].iloc[0]
                st.write(f"- {f}: Ù…Ù‚Ø¯Ø§Ø± ÙØ¹Ù„ÛŒ = {val}")
                if 'sleep' in f.lower() and val < X[f].mean():
                    st.write('  - ØªÙˆØµÛŒÙ‡: Ø§ÙØ²Ø§ÛŒØ´ Ø®ÙˆØ§Ø¨ Ø¨Ù‡ Ù†Ø²Ø¯ÛŒÚ© Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒâ€ŒØ´Ø¯Ù‡.')
                if 'caffe' in f.lower() and val > X[f].mean():
                    st.write('  - ØªÙˆØµÛŒÙ‡: Ú©Ø§Ù‡Ø´ Ù…ØµØ±Ù Ú©Ø§ÙØ¦ÛŒÙ†.')

        if st.button('ØªÙˆÙ„ÛŒØ¯ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø¨Ø±Ø§ÛŒ Ú©Ù„ Ø¯ÛŒØªØ§Ø³Øª Ùˆ Ø¯Ø§Ù†Ù„ÙˆØ¯ CSV'):
            df_out = df.copy()
            df_out['predicted_'+str(target)] = model.predict(X)
            st.download_button('Ø¯Ø§Ù†Ù„ÙˆØ¯ CSV', data=df_out.to_csv(index=False).encode('utf-8'), file_name='predictions.csv')

        st.markdown('---')
        st.write('ğŸ“Œ Ù†Ú©Ø§Øª Ø§Ø®Ù„Ø§Ù‚ÛŒ: Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø­Ø³Ø§Ø³ Ø±Ø§ Ù…Ø­Ø§ÙØ¸Øª Ú©Ù†ÛŒØ¯. Ù…Ø¯Ù„ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ Ú©Ù„ÛŒÙ†ÛŒÚ©ÛŒ Ø¯Ø§Ø±Ø¯. Ø§ÛŒÙ† Ø§Ù¾ ØªÙˆØµÛŒÙ‡ Ù¾Ø²Ø´Ú©ÛŒ Ù†ÛŒØ³Øª.')
    else:
        st.info('Ù„Ø·ÙØ§Ù‹ ÛŒÚ© ÙØ§ÛŒÙ„ Ø¯Ø§Ø¯Ù‡ Ø¢Ù¾Ù„ÙˆØ¯ Ú©Ù†ÛŒØ¯ ØªØ§ Ø¢Ù†Ø§Ù„ÛŒØ² Ø¢ØºØ§Ø² Ø´ÙˆØ¯.')

# -------------------------
# Entry point
# -------------------------

if __name__ == '__main__':
    parser = argparse.ArgumentParser(description="Smart Women's Health Analyzer - fallback/streamlit app")
    parser.add_argument('--file', '-f', type=str, help='Path to CSV or Excel file')
    parser.add_argument('--target', '-t', type=str, default=None, help='Name of target column (optional)')
    parser.add_argument('--test-size', type=float, default=0.2, help='Test size fraction')
    parser.add_argument('--n-estimators', type=int, default=120, help='Number of trees for RandomForest')
    parser.add_argument('--random-state', type=int, default=42, help='Random seed')
    parser.add_argument('--output-prefix', type=str, default='output', help='Prefix for saved artifacts')
    args = parser.parse_args()

    if STREAMLIT_AVAILABLE:
        # If streamlit is available, run the Streamlit app
        run_streamlit_app()
    else:
        # CLI mode
        if not args.file:
            print('Streamlit is not installed in this environment. Running in CLI/fallback mode.')
            print('Please provide a data file with --file data.csv or install streamlit with `pip install streamlit` to use the web UI.')
            sys.exit(1)
        run_cli(args.file, target=args.target, test_size=args.test_size, n_estimators=args.n_estimators, random_state=args.random_state, output_prefix=args.output_prefix)
